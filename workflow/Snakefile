rule create_environment:
    shell:
        """
        mamba env create -f environment.yml --prefix ./.venv
        mamba run -p ./.venv pip install plip
        mamba run -p ./.venv ANARCI --build_models
        """

rule download_stcrdab_summary:
    output: "data/raw/stcrdab_summary.tsv"
    shell: "wget -O {output} https://opig.stats.ox.ac.uk/webapps/stcrdab-stcrpred/summary/all"


rule select_and_process_structures:
    input: "data/raw/stcrdab_summary.tsv"
    output: directory("data/interim/structures")
    resources:
        runtime="20m",
        mem="1GB",
        tasks=1
    script: "scripts/select_and_process_structures.py"

rule aggregate_interactions:
    input: "data/interim/structures"
    output: "data/interim/interactions.csv"
    resources:
        runtime="1m",
        mem="100MB"
    run:
        import glob
        import os
        import re

        import pandas as pd

        interactions = []
        for path in glob.glob(os.path.join(input[0], '*_interactions.csv')):
            interaction_df = pd.read_csv(path)
            interaction_df['complex_name'] = re.search(r'([0-9a-z]{4}_[a-zA-Z]{4,5})_interactions.csv', os.path.basename(path)).group(1)

            interactions.append(interaction_df)

        interactions = pd.concat(interactions)
        columns = ['complex_name', *(column_name for column_name in interactions.columns if column_name != 'complex_name')]
        interactions = interactions[columns]
        interactions.to_csv(output[0], index=False)

rule run_structures_summary_notebook:
    input: "data/interim/structures", "data/interim/interactions.csv"
    output: "data/flags/structures_summary_done.flag"
    resources:
        runtime="10m",
        mem="1GB",
        tasks=1
    shell:
        """
        papermill notebooks/structures_summary.ipynb notebooks/structures_summary.ipynb
        touch {output}
        """

rule create_apo_structures:
    input: "data/interim/structures"
    output: directory("data/interim/structures_apo")
    resources:
        runtime="5m",
        mem="1GB",
        tasks=1
    shell:
        """
        mkdir -p {output}

        for path in {input}/*.pdb; do
            name=$(basename $path .pdb)
            awk 'substr($0, 22, 1) == "E" || substr($0, 22, 1) == "D"' $path > "{output}/${{name}}_tcr.pdb"
            awk 'substr($0, 22, 1) == "A" || substr($0, 22, 1) == "B" || substr($0, 22, 1) == "C"' $path > "{output}/${{name}}_pmhc.pdb"
        done

        ref_tcr=$(ls {output}/*_tcr.pdb | sort | head -n1)
        for path in {output}/*_tcr.pdb; do
            pymol -c -d "load {output}/${{ref_tcr}}, ref; load ${{path}}, mov; align mov, ref; save ${{path}}, mov; quit"
        done

        ref_pmhc=$(ls {output}/*_pmhc.pdb | sort | tail -n1)
        for path in {output}/*_pmhc.pdb; do
            pymol -c -d "load {output}/${{ref_pmhc}}, ref; load ${{path}}, mov; align mov, ref; save ${{path}}, mov; quit"
        done
        """

rule package_data:
    input:
        readme="README_DATASET.md",
        structures="data/interim/structures",
        interactions="data/interim/interactions.csv",
        apo_structures="data/interim/structures_apo",
        _flag="data/flags/structures_summary_done.flag"
    output: "data/processed/structures.zip"
    resources:
        runtime="5m",
        mem="1GB",
        tasks=1
    shell:
        """
        mkdir $TMPDIR/structures

        # Readme
        cp {input.readme} $TMPDIR/structures/README.md

        # Structural data
        cp {input.structures}/*.pdb $TMPDIR/structures/
        cp {input.structures}/structures_summary.csv $TMPDIR/structures/
        cp {input.interactions} $TMPDIR/structures/
        cp -r {input.apo_structures} $TMPDIR/structures/

        # Export notebook
        jupyter nbconvert --no-input --to html --output-dir $TMPDIR/structures/ notebooks/structures_summary.ipynb

        # Zip everything together
        current_dir=$(pwd)
        cd $TMPDIR
        zip -r $current_dir/{output} structures

        # Cleanup temp files
        rm -r structures
        """
